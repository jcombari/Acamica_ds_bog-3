{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\rorodriguez\\appdata\\local\\pip\\cache\\wheels\\ea\\a7\\19\\fac0a408a586265eb374005308a7553d4494ab41b2fd88f5bc\\watson_developer_cloud-2.10.1-cp37-none-any.whl\n",
      "Collecting websocket-client==0.48.0\n",
      "  Using cached websocket_client-0.48.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from watson-developer-cloud) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0,>=2.0 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from watson-developer-cloud) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from websocket-client==0.48.0->watson-developer-cloud) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from requests<3.0,>=2.0->watson-developer-cloud) (2019.11.28)\n",
      "Installing collected packages: websocket-client, watson-developer-cloud\n",
      "Successfully installed watson-developer-cloud-2.10.1 websocket-client-0.48.0\n",
      "Collecting watson-machine-learning-client\n",
      "  Using cached watson_machine_learning_client-1.0.378-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from watson-machine-learning-client) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from watson-machine-learning-client) (2.22.0)\n",
      "Processing c:\\users\\rorodriguez\\appdata\\local\\pip\\cache\\wheels\\8c\\4b\\43\\e3606c88bd7f0169a587d82ad79f5f826f91983106eec3e22b\\ibm_cos_sdk-2.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from watson-machine-learning-client) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from watson-machine-learning-client) (4.42.1)\n",
      "Collecting lomond\n",
      "  Using cached lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied, skipping upgrade: pandas in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from watson-machine-learning-client) (1.0.1)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from requests->watson-machine-learning-client) (2.8)\n",
      "Processing c:\\users\\rorodriguez\\appdata\\local\\pip\\cache\\wheels\\49\\c8\\20\\8139a0a66f56909d5e96bfa423067020e6b5736c3a5b53f51c\\ibm_cos_sdk_s3transfer-2.6.2-py2.py3-none-any.whl\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Processing c:\\users\\rorodriguez\\appdata\\local\\pip\\cache\\wheels\\16\\82\\37\\f124bfe619e72fc1c5f9abbd018bf2ee129f131bf2ede5ebcc\\ibm_cos_sdk_core-2.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from lomond->watson-machine-learning-client) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from pandas->watson-machine-learning-client) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from pandas->watson-machine-learning-client) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\rorodriguez\\.conda\\envs\\ibmc\\lib\\site-packages (from pandas->watson-machine-learning-client) (1.18.1)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Using cached docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Installing collected packages: docutils, jmespath, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, lomond, tabulate, watson-machine-learning-client\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "Successfully installed docutils-0.15.2 ibm-cos-sdk-2.6.2 ibm-cos-sdk-core-2.6.2 ibm-cos-sdk-s3transfer-2.6.2 jmespath-0.10.0 lomond-0.3.3 tabulate-0.8.7 watson-machine-learning-client-1.0.378\n"
     ]
    }
   ],
   "source": [
    "# # Descomenten si todavía no instalaron el cliente\n",
    "!pip install --upgrade watson-developer-cloud\n",
    "!pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando el Dataset\n",
    "Importamos el dataset de review de películas que utilizamos para la entrega número 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá deben completar con la dirección donde tienen el dataset de películas que usamos para la entrega 5\n",
    "moviedir = r'./movie_reviews' \n",
    "movie_reviews = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este dataset consistía de un diccionario donde la key `data` contenía el texto de la review, y la key `target` tenía un 1 si ese review fue positivo y un 0 si fue negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armando el pipeline\n",
    "Primero, antes de definir nuestro workflow de trabajo, vamos a separar en Train y Test nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    movie_reviews.data, movie_reviews.target, test_size = 0.20, stratify=movie_reviews.target, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, vamos a definir un workflow muy simple donde primero vectorizamos el texto, aplicamos una transofrmación tf-idf y luego clasificamos con un SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vect = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ponemos estos dos pasos adentro de un único objeto, una instancia de un objeto Pipeline, al que llamamos `pipeline`. Al igual que los otros modelos, también cuenta con las funciones `fit` y `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = Pipeline([('vect',vect),('tfidf',tfidf),('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podríamos fitear y usar el modelo para predecir de manera local corriendo la siguiente linea.\n",
    "# Pero no es la idea, vamos a correrlo desde el servidor.\n",
    "pipeline2 = Pipeline([('vect',vect),('tfidf',tfidf),('clf',clf)])\n",
    "pipeline2.fit(X_train, y_train)\n",
    "#pipeline2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: watson-machine-learning-client in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (1.0.378)\n",
      "Requirement already satisfied, skipping upgrade: pandas in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (0.25.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (4.36.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: lomond in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (2.6.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from watson-machine-learning-client) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from pandas->watson-machine-learning-client) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from pandas->watson-machine-learning-client) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from pandas->watson-machine-learning-client) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from requests->watson-machine-learning-client) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from lomond->watson-machine-learning-client) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-core==2.6.2 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.6.2)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-s3transfer==2.6.2 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.6.2)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from ibm-cos-sdk->watson-machine-learning-client) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from ibm-cos-sdk-core==2.6.2->ibm-cos-sdk->watson-machine-learning-client) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "# Descomentá la siguiente linea para hacer la instalación\n",
    "#!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from sklearn) (0.23.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from scikit-learn->sklearn) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from scikit-learn->sklearn) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\rorodriguez\\documents\\anaconda3\\envs\\datascience2\\lib\\site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1321 sha256=e48fa7f7f7a8e90f9a1f5bf026c1ee4cd020f0ac2ac5dec6f166470199a8c684\n",
      "  Stored in directory: C:\\Users\\rorodriguez\\AppData\\Local\\pip\\Cache\\wheels\\76\\03\\bb\\589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install sklearn --upgrade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar Watson Machine Learning API es necesario crear un servicio desde:\n",
    "https://console.bluemix.net/catalog/services/machine-learning.\n",
    "\n",
    "Una vez creado ir a la lista de la izquierda a `Service Credentials` y crear nuevas credenciales. \n",
    "\n",
    "Para ver las credenciales hay que tocar en `Copy Credentials`. \n",
    "De allí copiar los datos necesarios para completar el código de la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wml_credentials={\n",
    "#  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "#  \"access_key\": \"\", # figura como apikey\n",
    "#  \"username\": \"\",\n",
    "#  \"password\": \"\",\n",
    "#  \"instance_id\": \"\"\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials={\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los datos del modelo a publicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"Nombre\", \n",
    "               client.repository.ModelMetaNames.NAME: \"Reviews classification nuevo\",\n",
    "               client.repository.DefinitionMetaNames.RUNTIME_NAME: 'python',\n",
    "               client.repository.DefinitionMetaNames.RUNTIME_VERSION: '3.6'}\n",
    "\n",
    "# Si quieren usar tensorflow, pueden especificar la versión como:\n",
    "#client.repository.DefinitionMetaNames.NAME: 'my_training_definition',\n",
    "#client.repository.DefinitionMetaNames.FRAMEWORK_NAME: 'tensorflow',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subimos el modelo a la nube con `client.repository.store_model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = client.repository.store_model(model=pipeline, \n",
    "                                                meta_props=model_props, \n",
    "                                                training_data=X_train, \n",
    "                                                training_target=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'guid': '213766ff-1a02-42b5-a441-785be283054e',\n",
       "  'url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/ff370bd5-de39-4909-9a98-32809c04a020/published_models/213766ff-1a02-42b5-a441-785be283054e',\n",
       "  'created_at': '2020-05-18T22:18:29.918Z',\n",
       "  'modified_at': '2020-05-18T22:18:29.995Z'},\n",
       " 'entity': {'runtime_environment': 'python-3.6',\n",
       "  'learning_configuration_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/ff370bd5-de39-4909-9a98-32809c04a020/published_models/213766ff-1a02-42b5-a441-785be283054e/learning_configuration',\n",
       "  'author': {'name': 'Ronald'},\n",
       "  'name': 'Reviews classification nuevo',\n",
       "  'label_col': 'l1',\n",
       "  'learning_iterations_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/ff370bd5-de39-4909-9a98-32809c04a020/published_models/213766ff-1a02-42b5-a441-785be283054e/learning_iterations',\n",
       "  'training_data_schema': {'features': {'type': 'list',\n",
       "    'fields': [{'name': 'f1', 'type': 'bytes'}]},\n",
       "   'labels': {'type': 'ndarray', 'fields': [{'name': 'l1', 'type': 'int'}]}},\n",
       "  'feedback_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/ff370bd5-de39-4909-9a98-32809c04a020/published_models/213766ff-1a02-42b5-a441-785be283054e/feedback',\n",
       "  'latest_version': {'url': 'https://us-south.ml.cloud.ibm.com/v3/ml_assets/models/213766ff-1a02-42b5-a441-785be283054e/versions/0cb17b2b-8bfe-44c9-84ae-68127d7bdf95',\n",
       "   'guid': '0cb17b2b-8bfe-44c9-84ae-68127d7bdf95',\n",
       "   'created_at': '2020-05-18T22:18:29.995Z'},\n",
       "  'model_type': 'scikit-learn-0.22',\n",
       "  'deployments': {'count': 0,\n",
       "   'url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/ff370bd5-de39-4909-9a98-32809c04a020/published_models/213766ff-1a02-42b5-a441-785be283054e/deployments'},\n",
       "  'evaluation_metrics_url': 'https://us-south.ml.cloud.ibm.com/v3/wml_instances/ff370bd5-de39-4909-9a98-32809c04a020/published_models/213766ff-1a02-42b5-a441-785be283054e/evaluation_metrics',\n",
       "  'input_data_schema': {'features': {'type': 'list',\n",
       "    'fields': [{'name': 'f1', 'type': 'bytes'}]},\n",
       "   'labels': {'type': 'ndarray', 'fields': [{'name': 'l1', 'type': 'int'}]}}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el uid del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos el id con el cual nos vamos a referir al modelo\n",
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ----------------------------  ------------------------  -----------------\n",
      "GUID                                  NAME                          CREATED                   FRAMEWORK\n",
      "213766ff-1a02-42b5-a441-785be283054e  Reviews classification nuevo  2020-05-18T22:18:29.918Z  scikit-learn-0.22\n",
      "------------------------------------  ----------------------------  ------------------------  -----------------\n"
     ]
    }
   ],
   "source": [
    "models_details = client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos cargar el modelo a partir de su `uid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = client.repository.load(published_model_uid)\n",
    "test_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc score:  0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85       200\n",
      "           1       0.83      0.88      0.85       200\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.85      0.85       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"roc_auc score: \", roc_auc_score(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
