{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensambles\n",
    "\n",
    "A lo largo del notebook vamos a trabajar con el siguiente dataset:\n",
    "\n",
    "https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Volvemos a cargas las librerías, importar el dataset y limpiarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DS_Encuentro_27_Weather.csv\")\n",
    "# Columnas con muchos NaNs\n",
    "columnas_descartables = ['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date']\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "data = data.dropna()\n",
    "\n",
    "# Columnas con variables categoricas\n",
    "columnas_descartables = ['WindGustDir','WindDir9am','WindDir3pm','RainToday']\n",
    "data = data.drop(columns=columnas_descartables)\n",
    "\n",
    "# Variables correlacionadas\n",
    "data = data.drop(columns=['Temp3pm', 'Pressure9am'])\n",
    "\n",
    "# Mapeo\n",
    "data['RainTomorrow'] = data['RainTomorrow'].map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Boosting\n",
    "\n",
    "El objetivo de boosting es generar un modelo fuerte a partir de entrenar sucesivamente modelos débiles y combinar sus resultados. La idea es que cada modelo débil que agrego se enfoque en las instancias que fueron clasificadas erroneamente hasta el momento. Empecemos por decidir sobre que fetures del dataset vamos a trabajar (si trabajan sobre 2, luego podrán visualizar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos sobre que coolumnas queremos trabajar\n",
    "columnas_entrenamiento = ['MaxTemp', 'Humidity3pm']\n",
    "X = COMPLETAR\n",
    "y = COMPLETAR\n",
    "\n",
    "# Separamos los datos en train y test (held-out) - Utilice un 30% del dataset como test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=COMPLETAR, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este tipo de ensamble se enfoca en mejorar el sesgo de los modelos individuales a partir de los cuales está construido, por lo cual se suele usar modelos de alto sesgo y baja varianza.\n",
    "\n",
    "1. Empiece por importar el clasificador AdaBoostClassifier y el modelo que usaremos como estimador debil, el DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Defina el modelo de manera que utilice 250 árboles de profundidad dos (2). Luego probaremos que sucede para mayores profundidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=COMPLETAR),algorithm='SAMME', n_estimators=250)\n",
    "# Entrenamos el modelo\n",
    "ada_clf.fit(COMPLETAR, COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calcule el error sobre el training set y sobre el test set. En base a estos resultados, ¿les parece que este ensamble está inclinado hacia el sesgo o hacia la varianza?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = COMPLETAR\n",
    "y_test_pred = COMPLETAR\n",
    "print('Accuracy sobre el test set: ',COMPLETAR)\n",
    "print('Accuracy sobre el train set: ',COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Veamos ahora cómo es la distribución de los pesos de cada árbol. Para esto vamos a graficar el número del árbol vs el peso que el algoritmo le está dando para la clasificación final. Además, graficaremos también el accuracy de cada arbol sobre el training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede que el algoritmo termine antes de agregar todos los arboles\n",
    "# Tomamos entonces la cantidad de arboles que realmente tiene el ensamble\n",
    "numero_arboles = len(ada_clf)\n",
    "\n",
    "# En la variable estimator_weights_ esta el peso de cada arbol\n",
    "pesos = ada_clf.estimator_weights_[:numero_arboles]\n",
    "\n",
    "# Calculamos el accuracy DE CADA ARBOL en el ensamble. En estimator_errors_ esta el error que comete cada uno.\n",
    "errores_arboles = ada_clf.estimator_errors_[:numero_arboles]\n",
    "# Como puede calcular el accuracy de cada arbol a partir de saber el error que comete cada uno?\n",
    "accuracy_arboles = COMPLETAR\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.subplot(121)\n",
    "# En el eje 'x' ponemos el índice (número) de cada arbol, en el 'y' los pesos\n",
    "plt.plot(range(1, numero_arboles + 1), COMPLETAR)\n",
    "plt.ylabel('Peso')\n",
    "plt.xlabel('Número de árbol')\n",
    "plt.ylim((0, pesos.max() * 1.1))\n",
    "plt.xlim((-20, numero_arboles + 20))\n",
    "plt.subplot(122)\n",
    "# En el eje 'x' ponemos el índice (número) de cada arbol, en el 'y' el accuracy de cada arbol\n",
    "plt.plot(range(1, numero_arboles + 1), COMPLETAR)\n",
    "plt.ylabel('Accuracy en trainin set')\n",
    "plt.xlabel('Número de árbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ¿Le parece relevante la contribución de todos los árboles?¿Cómo se relaciona el accuracy de cada árbol con el peso que le damos en la clasificación final?\n",
    "\n",
    "6. Veamos cómo cambia el error en el training set y en el test set a medida que agregamos árboles. Para esto vamos a utilizar un metodo llamado `staged_predict`, que nos devuelve la predicción del ensamble en cada instancia en que fuimos agregandole un nuevo estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos listas vacias donde vamos a \"appendear\" (agregar) los valores\n",
    "accuracy_test = COMPLETAR\n",
    "accuracy_train = COMPLETAR\n",
    "\n",
    "# Calculamos el accuracy sobre el test set\n",
    "for prediccion_test in ada_clf.staged_predict(X_test):\n",
    "    accuracy_test.append(metrics.accuracy_score(prediccion_test,COMPLETAR))\n",
    "    \n",
    "# Calculamos el accuracy sobre el training set    \n",
    "for prediccion_train in ada_clf.staged_predict(X_train):  \n",
    "    accuracy_train.append(metrics.accuracy_score(prediccion_train,COMPLETAR))\n",
    "    \n",
    "plt.plot(range(1, len(accuracy_test) + 1), accuracy_test, label = 'Test')\n",
    "plt.plot(range(1, len(accuracy_test) + 1), accuracy_train, label = 'Train')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy en el test set')\n",
    "plt.xlabel('Número de árboles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Grafiquemos la frontera de decisión del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 #para no graficar todos los puntos y saturar el grafico\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "ax = sns.scatterplot(X_test[::N].MaxTemp, X_test[::N].Humidity3pm, hue=y_test[::N], palette='Set2')\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                      np.linspace(*ylim, num=200))\n",
    "Z = ada_clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Repita lo realizado hasta ahora pero utilice árboles de profundidad diez. Preste atención a las curvas de accuracy en train y test y al gráfico de la frontera. ¿Qué le parece que esta sucediendo en este caso?\n",
    "\n",
    "9. Instalar y entrenar un modelo con `XGBoost`. Explorar diferencias y similitudes con `Adaboost`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
