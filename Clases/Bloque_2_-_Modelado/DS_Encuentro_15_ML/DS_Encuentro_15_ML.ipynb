{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Aprendizaje Supervisado - Clasificación\n",
    "\n",
    "En este notebook, comenzamos a trabajar en los problemas de **Clasificación**, una de las tareas más importantes dentro de Machine Learning (dentro, a su vez, de lo que llamamos Aprendizaje Supervisado). Clasificación en Machine Learning consiste en aprender etiquetas discretas *y* a partir de un conjunto de features *X* (que pueden ser uno, dos, o muchos más) tomando como muestra un conjunto de instancias.\n",
    "\n",
    "Vamos a comenzar introduciendo un dataset sintético de dos features y dos clases. Y trataremos de aprender a clasificarlo usando nuestro primer modelo, Árbol de Decisión.\n",
    "\n",
    "### Modelo: Árbol de decisión\n",
    "\n",
    "El primer modelo de clasificación que vamos a utilizar es un Árbol de decisión.\n",
    "\n",
    "Dadas varias instancias con un determinados grupo de features **X** y unas determinadas etiquetas objetivo **y**, el árbol de desición aprende AUTOMÁTICAMENTE reglas (de mayor o menor) sobre cada feature de manera de poder decidir que etiqueta le corresponde a cada uno.\n",
    "\n",
    "### Ejemplo demostrativo\n",
    "Vamos a generar automáticamente un grupo de 1000 instancias con features llamados *x1* y *x2* - agrupados en una única variable `X`- a los cuales les vamos a asignar una etiqueta `y`, la cual puede valer 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que nos ayuda a graficar\n",
    "# No hace falta que comprandan este bloque de código.\n",
    "\n",
    "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, clim=(y.min(), y.max()),\n",
    "                           zorder=1)\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda genera nuestro dataset sintético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, centers=2,\n",
    "                  random_state=0, cluster_std=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a graficar las diferentes instancias que generamos como puntos en el plano (x1,x2) y les asignamos un color distinto segun cual sea su etiqueta `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos entrenar un árbol de decisión para clasificar nuestras instancias, primero debemos crear un objeto correspondiente al modelo. Este objeto será de de la clase `DecisionTreeClassifier`, la cual importamos desde la librería scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Creamos un objeto arbol\n",
    "tree = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que nuestro modelo fue creado, precisamos entrenarlo sobre nuestros datos. Esto lo logramos con el método `fit` que poseen todas las clases correspondientes a modelos de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función que definimos arriba nos permite explorar cómo es el dominio de decisión de nuestro arbol una vez que lo entrenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(tree, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico aquellos puntos (instancias) que queden sobre un fondo de su mismo color son aquellos que están bien clasificados por el modelo. Esto quiere decir que que si usamos el modelo para calificar su etiqueta 'y' a partir de sus coordenadas 'x1' y 'x2', este nos daría la misma etiqueta original del punto. \n",
    "\n",
    "En cambio, aquellos puntos que queda sobre un fondo de otro color son puntos para los cuales el modelo nos estaría dando una etiqueta distinta a la etiqueta original de esa instancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos podríamos preguntar luego: ¿cuál es el porcentaje de instancias bien clasificadas por el modelo?\n",
    "\n",
    "Para responder esto usaremos el método `predict`. Este método nos indica la etiqueta asignada por el modelo a cada instancia del set de entrenamiento. Luego con la función `accuracy_score` podemos calcular el porcentaje de aciertos que obtenemos al comparar nuestra predicción `y_pred` contra la clase original `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predecimos sobre nuestro set de entrenamieto\n",
    "y_pred = tree.predict(X)\n",
    "\n",
    "# Comaparamos con las etiquetas reales\n",
    "accuracy_score(y_pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para pensar y probar**:\n",
    "1. ¿Qué ocurre si modifican el valor de `cluster_std` en la función `make_blobs`?¿En qué casos será más fácil - o difícil - la tarea de clasificación?\n",
    "2. ¿Qué ocurre si modifican el valor de `centers` en la función `make_blobs`?¿En qué cambia la formulación del problema de clasificación?\n",
    "3. Hay algunas características de esta formulación que tal vez les llamen la atención. En el caso binario, un problema de clasificación consiste en encontrar una **frontera** entre puntos que deje a un lado los que pertenecen a una clase, y del otro lado los puntos de la otra clase. Para convencerse (¡o no!):\n",
    "    1. Elegir un problema de Clasificación Binario (al estilo Spam/No-Spam, Titanic Sobrevivió/No-Sobrevivió, etc.). Inventar - a mano - dos atributos, algunas instancias, y graficar. Luego, dibujar una frontera de decisión (siempre a mano, no tienen que programar). Un ejemplo podría ser: para clasificar vinos blancos y vinos tintos, un atributo podría ser el color y el otro podría ser el dulzor.\n",
    "    2. ¿Qué ocurre si en lugar de dos atributos tenemos tres?¿Qué forma tendrá la frontera? Y si en vez de tres atributos tenemos cuatro?¿Se podrá visualizar?\n",
    "    3. Para googlear (no hace falta hacerlo ahora): ¿Qué es la maldición de la dimensión/dimensionalidad (curse of dimensionality)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio - Dataset del Titanic\n",
    "\n",
    "\n",
    "### Problema a resolver\n",
    "El problema que nos planteamos es el siguiente: supongamos que tenemos el dataset de Titanic, donde conocemos varios datos de cada pasajero, incluído si sobrevivió o no al accidente. Pero nos dicen que se encontraron registros de nuevos pasajero, de los cuales se conocen todos los datos pero no saben si sobrevivieron. ¿Podremos generar un algoritmo que nos indique (en base a la información de los pasajeros que sí conocemos su estado) si esos otros pasajeros sobrevivieron o no?\n",
    "\n",
    "Como ven este problema es de clasificación: tenemos que decidir la categoría (sobrevivió o no) de cada instancia en base a ciertos datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "A lo largo de la primera parte del curso, aprendimos a importar y limpiar nuesto dataset antes de empezar a analizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el Dataset\n",
    "df = pd.read_csv('DS_Clase_05_titanic.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar en este problema, vamos a quedarnos solo con algunos de los features disponibles en el dataset.\n",
    "\n",
    "**Ejercicio**: descarte del dataset las columnas `Cabin`, `PassengerId`, `Name`, `Ticket`, `Embarked`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([COMPLETAR], axis=COMPLETAR,inplace=COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** ¿Cuántas instancias con valores faltantes quedan? Descarte del Dataset dichas instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Note que de los features restantes, solo uno es de tipo categórico. ¿Cuál es? Use la función `LabelEncoder` de scikit-learn para cambiarlo a una variables numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df[COMPLETAR] = le.fit_transform(df[COMPLETAR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos\n",
    "\n",
    "Muy bien, ahora tenemos un dataset reducido, sólo con features numéricos y sin valores faltantes. Recordemos que nuestro objetivo es predecir si un pasajero sobrevivió o no. Por ende nuestra columna objetivo será `Survived`.\n",
    "\n",
    "El objetivo en esta pequeña exploración del dataset será saber cuales de los features (las columnas) serán de mayor utilidad para predecir si la persona sobrevivió o no.\n",
    "\n",
    "Primero, vemos que porcentaje de pasajeros sobrevivió:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived', data=df) #equivelante a sns.countplot(df.Sex)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el porcentaje numérico\n",
    "cuenta_sobrevivientes = df['Survived'].value_counts()\n",
    "porcentaje = 100*(cuenta_sobrevivientes.values[0]/df.shape[0])\n",
    "print('Porcentaje de no sobrevivientes:',porcentaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que un 60% de los pasajeron no sobrevivieron. Es decir que, si ante la pregunta \"¿Sobrevivió este pasajero?\" nuestra respuesta fuese siempre \"No\", estaríamos acertando el 60% de las veces. Éste será nuestro Benchmark. Nuestro modelo tiene que, mínimamento, poder desempeñarse mejor que esto.\n",
    "\n",
    "Vamos a explorar cuales de los features parecen que nos pueden ayudar a decidir mejor si un pasajero sobrevivió o no. Para empezar, vamos a implementar un Árbol de decisión que solo tendrá dos variables de entrada, por lo tanto debemos elegir las dos columnas que nos parezcan más adecuadas. Veamos como correlacionan las variables del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tocar este código\n",
    "def plot_corre_heatmap(corr):\n",
    "    '''\n",
    "    Definimos una función para ayudarnos a graficar un heatmap de correlación\n",
    "    '''\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(corr, cbar = True,  square = False, annot=True, fmt= '.2f'\n",
    "                ,annot_kws={'size': 15},cmap= 'coolwarm')\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.yticks(rotation = 45)\n",
    "    # Arreglamos un pequeño problema de visualización\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "plot_corre_heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mire con atención el gráfico anterior y recuerde que nuestra columna/fila a predecir es la primera ,`Survived`.\n",
    "\n",
    "**Ejercicio:** ¿Cuáles dos columnas eligiría para usar como variables predictoras en el modelo? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo y evaluación\n",
    "\n",
    "Veamos ahora que tan bien puede predecir el árbol de decisión sobre el dataset.\n",
    "\n",
    "**Ejercicio**: Crear un objeto de la clase `DecisionTreeClassifier` (que importamos desde `sklearn.tree`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from COMPLETAR import COMPLETAR\n",
    "\n",
    "# Creamos un objeto arbol\n",
    "tree = COMPLETAR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** definir nuestras variables predictoras con las cuales vamos a entrenar el modelo, a las que llamaremos `x_train`. Usar las columas del dataset que elegimos del ejercicio anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[COMPLETAR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** definir el atributo objetivo que buscamos predecir. Lo llamaremos `y_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[COMPLETAR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.COMPLETAR(COMPLETAR, COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro árbol ya está entrenado. \n",
    "\n",
    "Ahora vamos a ver cuales son las etiquetas que el modelo le asigna a cada una de las instancias. Es decir vamos a pasarle al modelo el valor de `Pclass` y de `Sex`, y éste nos dirá si el pasajero sobrevivió o no (`y_pred`). Estas son las predicciones del modelo, pero nosotros conocemos además el verdadero paradero de estos pasajeros (son los valores de `y_train`). \n",
    "\n",
    "Comparando ambos valores (`y_pred` e `y_train`) podemos conocer el *accuracy* (porcentaje de aciertos) de nuestro modelo sobre el training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos sobre nuestro set de entrenamieto\n",
    "y_pred = tree.COMPLETAR(COMPLETAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Comaparamos con las etiquetas reales\n",
    "accuracy_score(COMPLETAR,COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos un 80%, apenas un 20% más que nuestro Benchmark.\n",
    "\n",
    "Pongamos ahora toda la carne al asador, y pasémosle al modelo todos los datos que tenemos disponibles en el dataset, no sólo dos columnas. Veamos si esto mejora las predicciones del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "y_train = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos sobre nuestro set de entrenamieto\n",
    "y_pred = tree.predict(x_train)\n",
    "\n",
    "# Comaparamos con las etiquetas reales\n",
    "accuracy_score(y_pred,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ahora sí tenemos una mejora sustancial sobre nuestro Benchmark!\n",
    "\n",
    "**Ejercicio:** Si bien parece que nuestro clasificador funciona muy bien prediciendo sobre el dataset de entrenamiento, \n",
    "\n",
    "* ¿Creen que lo haría igual sobre nuevos datos (pasajeros con los cuales no lo entrenamos)? ¿Esperarían que fuese mejor o peor el desempeño?\n",
    "\n",
    "* Si uno quisiese tener una estiamación más certera sobre el rendimiento del modelo sobre nuevos datos ¿Qué se les ocurre que se podría hacer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
