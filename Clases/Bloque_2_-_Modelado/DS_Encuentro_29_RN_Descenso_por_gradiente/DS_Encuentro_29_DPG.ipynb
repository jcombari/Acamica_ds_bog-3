{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "## Preliminares\n",
    "\n",
    "### 1. Funciones de costo\n",
    "\n",
    "Recordemos que una función lineal tiene la forma $y = mx + b$, donde $m$ es la pendiente y $b$ es la ordenada al origen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os #esta libreria permite trabajar con funciones del sistema operativo \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,100)\n",
    "m_0 = 2 # el verdadero valor de la pendiente\n",
    "b_0 = -3 # el verdadero valor de la ordenada al origen\n",
    "y = m_0*x + b_0 + 0.25*np.random.randn(x.size) #agregamos ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y, label = 'datos')\n",
    "plt.plot(x, m_0*x + b_0, '--', c = 'r', label = 'recta teorica')\n",
    "plt.ylabel('Variable a Predecir')\n",
    "plt.xlabel('Feature')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "if False:\n",
    "    plt.savefig('Datos_ajuste_.png', dpi= 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, uno tiene ciertos datos y de esos datos quiere estimar los valores del modelo, en este caso, la pendiente y ordenada al origen de la recta. La hipótesis que vamos a utilizar es que la recta que mejor aproxime los datos va a ser la recta teórica que \"genera\" los datos.\n",
    "\n",
    "Pero para definir la recta que \"mejor aproxime\" tenemos que cuantificar que es, precisamente, aproximar bien. Para ello usamos una métrica. En este caso vamos a usar MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y,y_pred):\n",
    "    '''Calcula Mean Squared Error'''\n",
    "    assert(len(y) == len(y_pred))\n",
    "    n = len(y)\n",
    "    return ((y - y_pred)**2).sum()/n\n",
    "\n",
    "# def RMSE(y,y_pred):\n",
    "#     '''Calcula Root Mean Squared Error'''\n",
    "#     assert(len(y) == len(y_pred))\n",
    "#     cost = MSE(y,y_pred)\n",
    "#     return np.sqrt(cost)\n",
    "\n",
    "# def MAE(y,y_pred):\n",
    "#     '''Calcula Mean Absolut Error'''\n",
    "#     assert(len(y) == len(y_pred))\n",
    "#     n = len(y)\n",
    "#     return (np.abs(y - y_pred)).sum()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Un parametro libre**\n",
    "\n",
    "Supongamos que conocemos la ordenada al origen $b$, y solamente tenemos que obtener la pendiente $m$. Lo que podemos hacer entonces es *barrer* distintos valores para $m$ y ver a cuál corresponde el mínimo del costo. **Importante**: en este caso, la función de costo depende de un único parámetro, $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m_s = np.linspace(-5,5,1000)\n",
    "b = -3\n",
    "costos = []\n",
    "for m in m_s:\n",
    "    y_pred = m*x + b\n",
    "    costos.append(MSE(y,y_pred))\n",
    "\n",
    "costos = np.array(costos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_minimo = np.argmin(costos)\n",
    "\n",
    "plt.plot(m_s, costos)\n",
    "plt.scatter(m_s[indice_minimo], costos[indice_minimo], marker = '*', c = 'r')\n",
    "plt.xlabel('Pendiente')\n",
    "plt.ylabel('Costo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dos parámetros libres**\n",
    "\n",
    "Antes de continuar, piensen qué modificarían en el caso de tener que encontrar no uno sino dos parámetros libres. Es decir, $m$ y $b$. En este caso, ¿de cuántos parámetros depende la función de costo?¿Cómo será su visualización?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_s = np.linspace(-5,5,500)\n",
    "b_s = np.linspace(-5,0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "costos = []\n",
    "for m in m_s:\n",
    "    for b in b_s:\n",
    "        y_pred = m*x + b\n",
    "        costos.append(MSE(y,y_pred))\n",
    "costos = np.array(costos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms, Bs = np.meshgrid(m_s,b_s, indexing = 'ij')\n",
    "costos_matriz = costos.reshape(m_s.size, b_s.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_minimo = np.unravel_index(costos_matriz.argmin(), costos_matriz.shape)\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.gca()\n",
    "\n",
    "plt.pcolormesh(Ms, Bs,costos_matriz)\n",
    "ax.contourf(Ms, Bs, costos_matriz)\n",
    "plt.colorbar()\n",
    "plt.scatter(Ms[idxs_minimo], Bs[idxs_minimo])\n",
    "plt.title('Costo en el minimo:' + str(costos_matriz[idxs_minimo]))\n",
    "plt.xlabel('Pendiente')\n",
    "plt.ylabel('Ordenada al origen')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(Ms, Bs,costos_matriz,linewidth=0.0, antialiased=False, cmap = 'plasma')\n",
    "# ax.view_init(0, 180)\n",
    "ax.set_xlabel('m')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('costo')\n",
    "plt.tight_layout()\n",
    "plt.colorbar(surf)    \n",
    "# plt.savefig('costo_3d.png', dpi = 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_encontrado = Ms[idxs_minimo]\n",
    "b_encontrado = Bs[idxs_minimo]\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x,y, label = 'datos')\n",
    "plt.plot(x, m_0*x + b_0, '--', c = 'r', label = 'recta teorica')\n",
    "plt.plot(x, m_encontrado*x +b_encontrado, '.', c = 'g', label = 'recta encontrada')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Descenso por gradiente\n",
    "\n",
    "**Nota**: Para los que nunca hayan visto análisis matemático, no importa si no entienden lo que sigue. La idea que les tiene que quedar es que podemos obtener la dirección en la cual movernos para llegar al mínimo de la función de costo.\n",
    "\n",
    "\n",
    "Para hacer descenso por gradiente necesitamos las derivadas. Notar que la función de costo es función de la pendiente $m$ y la ordenada al origen $b$. Para simplificar, vamos a asumir que después de hacer varios reemplazos y algunas cuentas, la función de costo tiene la siguiente forma:\n",
    "\n",
    "$$MSE(m, b) = (m-2)^2 + (b+3)^2$$\n",
    "\n",
    "¿Están de acuerdo que el mínimo se obtiene para $m = 2$ y $b = -3$? Si no están de acuerdo, discutir con el compañero hasta que lo estén.\n",
    "\n",
    "Escribimos la función MSE, sus derivadas y el gradiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_m_y_b(m,b):\n",
    "    return (m-2)**2 + (b+3)**2\n",
    "\n",
    "def der_MSE_m(m,b):\n",
    "    '''Derivada de MSE respecto a m'''\n",
    "    return 2*(m-2)\n",
    "\n",
    "def der_MSE_b(m,b):\n",
    "    '''Derivada de MSE respecto a b'''\n",
    "    return 2*(b+3)\n",
    "\n",
    "def gradiente(m,b):\n",
    "    gradiente = np.array([der_MSE_m(m,b), der_MSE_b(m,b)])\n",
    "    return gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos un valor para $m$ y otro para $b$ y calculamos el gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_prueba = -2 #Solo aca tienen que cambiar\n",
    "b_prueba = -3 #Solo aca tienen que cambiar\n",
    "\n",
    "grad = gradiente(m_prueba, b_prueba)\n",
    "print(grad)\n",
    "\n",
    "### Esto es para que tenga norma 1. Ignorar\n",
    "grad = grad/np.linalg.norm(grad)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora graficamos la función de costo con menos el gradiente obtenido para el punto elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.gca()\n",
    "\n",
    "plt.pcolormesh(Ms, Bs,MSE_m_y_b(Ms, Bs))\n",
    "ax.contourf(Ms, Bs, MSE_m_y_b(Ms, Bs))\n",
    "plt.colorbar()\n",
    "\n",
    "plt.scatter(m_prueba,b_prueba, c=\"white\")\n",
    "plt.arrow(m_prueba,b_prueba, -grad[0], -grad[1], head_width=0.05, head_length=0.1, fc='white', ec='white')\n",
    "\n",
    "plt.xlabel('Pendiente')\n",
    "plt.ylabel('Ordenada al origen')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificar los valores de `m_prueba` y `b_prueba` y convercerse de que el negativo del gradiente apunta hacia el mínimo. **Importante**: ¿Cuánto vale el gradiente en el mínimo?\n",
    "\n",
    "\n",
    "\n",
    "**Descenso por gradiente**\n",
    "\n",
    "Descenso por gradiente consiste entonces en ir haciendo sucesivos pasos, siguiendo la dirección que marca el negativo del gradiente, hasta llegar al mínimo o muy cerca de él. En general:\n",
    "\n",
    "1. Empezamos con valores aleatorios de los parámetros.\n",
    "2. Repetimos tantas veces como sea necesario\n",
    "    1. Calculamos el gradiente (derivadas) de la función de costo respecto al valor actual de los parámetros.\n",
    "    2. Actualizamos los valores de los parámetros siguiendo menos la derivada para cada uno.\n",
    "    $$ m_{nuevo} = m_{viejo} - \\alpha * \\frac{dMSE(m,b)}{dm} $$\n",
    "    $$ b_{nuevo} = b_{viejo} - \\alpha * \\frac{dMSE(m,b}{db} $$\n",
    "      \n",
    "      \n",
    "Al **hiperparámetro** $\\alpha$ se lo conoce como *learning rate* y lo van a encontrar en casi todos los frameworks donde se implemente descenso por gradiente. Es, sin duda, uno de los principales hiperparámetros en cualquier desarrollo con redes neuronales.\n",
    "\n",
    "Lo implementamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -1   #por ahora, los elegimos a mano, pero deberia ser al azar\n",
    "b = -1   #por ahora, los elegimos a mano, pero deberia ser al azar\n",
    "\n",
    "max_steps = 500 # Modificar despues\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costos = []\n",
    "m_obtenidos = []\n",
    "b_obtenidos = []\n",
    "\n",
    "for step in range(max_steps):\n",
    "    costos.append(MSE_m_y_b(m,b))\n",
    "    m_obtenidos.append(m)\n",
    "    b_obtenidos.append(b)\n",
    "    m = m - alpha*der_MSE_m(m,b)\n",
    "    b = b - alpha*der_MSE_b(m,b)\n",
    "\n",
    "# Agregamos el ultimo paso que no lo hicimos\n",
    "costos.append(MSE_m_y_b(m,b))\n",
    "m_obtenidos.append(m)\n",
    "b_obtenidos.append(b)\n",
    "\n",
    "# Llevamos a arreglos\n",
    "costos = np.array(costos)\n",
    "m_obtenidos = np.array(m_obtenidos)\n",
    "b_obtenidos = np.array(b_obtenidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(costos)\n",
    "plt.xlabel('Paso')\n",
    "plt.ylabel('Costo')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(m_obtenidos)\n",
    "plt.axhline(m_0, linestyle = '--', c = 'r', label = 'm real')\n",
    "plt.xlabel('Paso')\n",
    "plt.ylabel('m')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(b_obtenidos)\n",
    "plt.axhline(b_0,  linestyle = '--', c = 'r', label = 'b real')\n",
    "plt.xlabel('Paso')\n",
    "plt.ylabel('b')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,6))\n",
    "ax = fig.gca()\n",
    "\n",
    "plt.pcolormesh(Ms, Bs,MSE_m_y_b(Ms, Bs))\n",
    "ax.contourf(Ms, Bs, MSE_m_y_b(Ms, Bs))\n",
    "plt.colorbar()\n",
    "plt.scatter(m_obtenidos[::5],b_obtenidos[::5], c=\"white\") #notar que grafica cada 5 pasos\n",
    "plt.xlabel('Pendiente')\n",
    "plt.ylabel('Ordenada al origen')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Anda siempre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,500)\n",
    "y = np.sin(10*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y, label = 'datos')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_s = np.linspace(0,50,1000)\n",
    "costos = []\n",
    "for w in w_s:\n",
    "    y_pred = np.sin(w*x)\n",
    "    costos.append(MSE(y,y_pred))\n",
    "costos = np.array(costos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w_s, costos)\n",
    "plt.xlabel('w')\n",
    "plt.ylabel('Costo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que hay muchos *mínimos locales* y un *mínimo absoluto*. En más dimensiones, es fácil confundir un mínimo local con el mínimo que estamos buscando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variantes de descenso por el gradiente (para acelerar/mejorar la convergencia)**:\n",
    "1. Stochastic gradient descent (SGD)\n",
    "2. Minibatches\n",
    "3. Agregar un término para dar inercia a la búsqueda, tratando de pasar por alto mínimos locales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: trabajando con imágenes.\n",
    "\n",
    "Vamos a ver las nociones básicas para abrir imágenes con Python. Una librería típica para usar es PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('domo.jpg')\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pillow permite hacer muchas cosas con la imagen. Explorar qué es cada una de las siguientes características. Recuerden ir a la documentación de la librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(im.width)\n",
    "# print(im.height)\n",
    "# print(im.bits)\n",
    "# print(im.getbands())\n",
    "print(im.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero, ¿qué es una imagen? Tal vez quede más claro si lo llevamos a un arreglo de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen_array = np.array(im)\n",
    "imagen_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagen_array) #notar que es una funcion de matplotlib, no pillow\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Averiguar como cortar y reescalar una imagen. También, jugar con las bandas y obtener imágenes en blanco y negro, con los colores cambiados, etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
