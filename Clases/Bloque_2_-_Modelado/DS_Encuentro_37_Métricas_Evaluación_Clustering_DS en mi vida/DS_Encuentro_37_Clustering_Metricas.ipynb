{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Métricas de Evaluación\n",
    "\n",
    "En esta segunda parte, vamos a trabajar con las métricas para determinar la bondad del proceso de clustering. Primero importamos todas las librerias que vamos a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set()\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.datasets.samples_generator import make_blobs, make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a generar nuevamente datasets. Recuerden que estos son datasets sintéticos, de los cuales ya sabemos de antemano la etiqueta que traen. El proceso de clustering nos permite identificar grupos que compartirían etiquetas cuando NO las conocemos y, en algunos casos, tampoco conocemos la cantidad de clases.\n",
    "\n",
    "1. Generamos dos dataset del tipo Blobs. Ambos con 2000 samples y 2 features. Uno con mayor desviación que el otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs, make_moons\n",
    "n_samples = 2000\n",
    "n_centros = 8\n",
    "\n",
    "X1, y1 = make_blobs(n_samples=n_samples, centers=n_centros, cluster_std=0.3, n_features=2, random_state=0)\n",
    "X2, y2 = make_blobs(n_samples=n_samples, centers=n_centros, cluster_std=0.6, n_features=2, random_state=2)\n",
    "\n",
    "# Preparamos un dataset con clusters que no sean simétricos\n",
    "random_state = 170\n",
    "X, y3 = make_blobs(n_samples=n_samples, centers=n_centros, cluster_std=0.6, random_state=3)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X3 = np.dot(X, transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Graficamos los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(COMPLETAR, legend ='full')\n",
    "plt.show()\n",
    "sns.scatterplot(COMPLETAR, legend ='full')\n",
    "plt.show()\n",
    "sns.scatterplot(COMPLETAR, legend ='full')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia al centroide\n",
    "\n",
    "Vamos a evaluar las particiones que realizamos mediante KMeans usando la distancia al centroide. La idea es que al variar el número de clúster K en el modelo, el valor de la distancia media de los datos al centroide más cercano va a variar. Queremos graficar esa curva para elegir el número de particiones óptimos con el metodo del codo.\n",
    "\n",
    "3. Preparamos una lista con las distancias medias a los centroides en el dataset 1. Vamos a probar un número de clústers que va de 2 a 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos una lista donde vamos a ir agregando las distancias medias\n",
    "lista_distancias_medias = []\n",
    "# Entrenamos un modelo para cada numero de cluster que queremos testear\n",
    "K = np.arange(2,14)\n",
    "for k in K:\n",
    "    # Definimos y entrenamos el modelo\n",
    "    km = KMeans(n_clusters=COMPLETAR)\n",
    "    km = km.fit(X1)\n",
    "    # Tomamos la suma de las distancias para todas las instancias del dataset\n",
    "    distancia_total = km.inertia_\n",
    "    # Calculamos la distancia media y agregamos a la lista\n",
    "    distancia_media = COMPLETAR\n",
    "    lista_distancias_medias.append(distancia_media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Graficamos la distancia media en función del núemro de clústers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "# Graficamos una linea continua y tambien unos puntos para resaltar los valores enteros de K.\n",
    "plt.plot(COMPLETAR, lw=3)\n",
    "plt.scatter(COMPLETAR,s=55,c='r')\n",
    "plt.xlabel('Cantidad de Clusters K')\n",
    "plt.ylabel('Inercia media')\n",
    "plt.title('Método del codo para el Dataset 1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repita el gráfico, pero esta vez para los datasets 2 y 3. Recomendamos copiar el código anterior y modificarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Usar el criterio para elegir el mejor numero de k en cada caso según la curva y graficar los clusters para cada dataset. Dejamos como ejemplo el dataset 3, donde de la curva tomamos el valor 6 como codo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino y entreno el modelo\n",
    "km = KMeans(n_clusters=6)\n",
    "km = km.fit(X3)\n",
    "# Obtengo la posición de los centros y las etiquetas\n",
    "etiquetas_ = km.labels_\n",
    "centros_ = km.cluster_centers_\n",
    "# Plotting the cluster centers and the data points on a 2D plane\n",
    "sns.scatterplot(X3[:, 0], X3[:, -1], hue = etiquetas_)\n",
    "sns.scatterplot(centros_[:, 0], centros_[:, 1],color='black', marker=\"+\", s=1000)\n",
    "plt.title('Data points and cluster centroids')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette\n",
    "\n",
    "Vamos a evaluar las particiones que realizamos mediante el valor de silhouette. La idea es que al variar los parámetros de los modelos de clustering, cambiará la distribución del valor de Silhouettes en los datos. Con esa distribución debemos elegir los mejores parametros posibles.\n",
    "\n",
    "7. Primero vamos a calcular únicamente el valor de silhouette promedio para distintos valores de K. La manera de hacerlo es igual a la que usamos para calcular los valores de distancia media, vamos a recorrer con un `for` los distintos modelos e ir agregando a una lista los valores. Esta vez, en lugar de calcular la distancia, vamos a calcular el valor de silhouette usando la función `silhouette_score`. Dejamos como ejemplo lo que sucede para el Dataset 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos una lista donde vamos a ir agregando los valores medios de silhouette\n",
    "lista_sil = []\n",
    "# Fiteammos un modelo para cada numero de cluster que queremos testear\n",
    "for k in range(2,14):\n",
    "    # Definimos y entrenamos el modelo\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X2)\n",
    "    \n",
    "    # Tomamos las etiquetas\n",
    "    etiquetas = km.labels_\n",
    "    \n",
    "    # Calculamos el silhouette \n",
    "    valor_medio_sil = silhouette_score(X2, etiquetas)\n",
    "    lista_sil.append(valor_medio_sil)\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(K, lista_sil, lw=3)\n",
    "plt.scatter(K, lista_sil,s=55,c='r')\n",
    "plt.xlabel('Cantidad de Clusters K')\n",
    "plt.ylabel('Silhouette media')\n",
    "plt.title('Silhouette media para el Dataset 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Repetir esta curva para los datasets 1 y 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. A modo demostrativo, les dejaremos un bloque de código que genera los gráficos de Silhouette para todas las instancias. Noten que pueden sacar información de qué tan buenas fueron las particiones del perfil de silhouettes de cada cluster. La línea verde punteada indica el valor medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca ponen el Dataset con el que quieren trabajar\n",
    "X_std = X2\n",
    "# Aca definen la lista de ks para los cuales quieren hacer un gráfico\n",
    "lista_k = [4, 6, 8, 10]\n",
    "\n",
    "for i, k in enumerate(lista_k):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    \n",
    "    # Run the Kmeans algorithm\n",
    "    km = KMeans(n_clusters=k)\n",
    "    labels = km.fit_predict(X_std)\n",
    "    centroids = km.cluster_centers_\n",
    "\n",
    "    # Get silhouette samples\n",
    "    silhouette_vals = silhouette_samples(X_std, labels)\n",
    "\n",
    "    # Silhouette plot\n",
    "    y_ticks = []\n",
    "    y_lower, y_upper = 0, 0\n",
    "    for i, cluster in enumerate(np.unique(labels)):\n",
    "        cluster_silhouette_vals = silhouette_vals[labels == cluster]\n",
    "        cluster_silhouette_vals.sort()\n",
    "        y_upper += len(cluster_silhouette_vals)\n",
    "        ax1.barh(range(y_lower, y_upper), cluster_silhouette_vals, edgecolor='none', height=1)\n",
    "        ax1.text(-0.03, (y_lower + y_upper) / 2, str(i + 1))\n",
    "        y_lower += len(cluster_silhouette_vals)\n",
    "\n",
    "    # Get the average silhouette score and plot it\n",
    "    avg_score = np.mean(silhouette_vals)\n",
    "    ax1.axvline(avg_score, linestyle='--', linewidth=2, color='green')\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_xlabel('Silhouette coefficient values')\n",
    "    ax1.set_ylabel('Cluster labels')\n",
    "    ax1.set_title('Silhouette plot for the various clusters', y=1.02);\n",
    "    \n",
    "    # Scatter plot of data colored with labels\n",
    "    ax2.scatter(X_std[:, 0], X_std[:, 1], c=labels)\n",
    "    ax2.scatter(centroids[:, 0], centroids[:, 1], marker='*', c='r', s=250)\n",
    "    ax2.set_xlim([-12, 12])\n",
    "    ax2.set_xlim([-12, 12])\n",
    "    ax2.set_xlabel('Eruption time in mins')\n",
    "    ax2.set_ylabel('Waiting time to next eruption')\n",
    "    ax2.set_title('Visualization of clustered data', y=1.02)\n",
    "    ax2.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Silhouette analysis using k = {k}',\n",
    "                 fontsize=16, fontweight='semibold', y=1.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA: Compresión de Imagen\n",
    "\n",
    "Como un extra les dejamos un pequeño algoritmo para comprimir imágenes usando K-means. \n",
    "\n",
    "IDEA en pocas palabras: en lugar de usar todos los colores posibles (combinaciones de 0 a 255 de los tres valores de Red Blue y Green) usamos una cantidad limitada que nosotros elegimos mediante un algoritmo de clustering.\n",
    "\n",
    "Explicación: Tomamos como datasets todos los pixeles, y los ponemos en el espacio de los tres valores de R G y B. y luego hacemos un proceso de clustering con K-means. La idea es que, en lugar de usar la escala de 0 a 255 en RGB para representar la imagen, usamos los valores de los K centroides. El sustento detrás de este método es que pixeles cercanos en la foto tendrán valores muy parecidos de RGB, con algún mínimo cambio. Por ejemplo, de haber una pared blaca en el fondo, todos los pixeles correspondientes a esa pared estaran muy cerca del (255,255,255) que es el Blanco puro en RGB. En lugar de usar un valor distinto para cada uno de estos pixeles, usamos un unico valor para definir el colo de todos ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "# Leemos la imagen obejtivo\n",
    "img = imread('domo.jpg')\n",
    "img_size = img.shape\n",
    "\n",
    "# Definimos el numero de Clusters (colores) a usar\n",
    "K= 30\n",
    "\n",
    "# Cambiamos sus dimensiones para que nos queden como instancias (filas) los pixeles\n",
    "# y como features (columnas) el valor correspondiente a Red, Blue y Green de cada uno.\n",
    "X = img.reshape(img_size[0] * img_size[1], img_size[2])\n",
    "\n",
    "# Corremos el algoritmo de clustering\n",
    "km = KMeans(n_clusters=K)\n",
    "km.fit(X)\n",
    "\n",
    "# Usamos los centroides para comprimir la imagen\n",
    "\n",
    "# Armamos un nuevo X donde en lugar de valores cualquiera en RGB ponemos alguno de los K clusters\n",
    "X_compressed = km.cluster_centers_[km.labels_]\n",
    "\n",
    "# Por las dudas nos aseguramos que los valores esten en la unidad y el rango correcto para una imagen jpg\n",
    "X_compressed = np.clip(X_compressed.astype('uint8'), 0, 255)\n",
    "\n",
    "# Volvemos la imagen a la forma original que debe tener\n",
    "X_compressed = X_compressed.reshape(img_size[0], img_size[1], img_size[2])\n",
    "\n",
    "# Graficamos las imagenes una al lado de la otra\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('Imagen Original')\n",
    "ax[1].imshow(X_compressed)\n",
    "ax[1].set_title('Imagen comprimida con solo K colores')\n",
    "for ax in fig.axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
